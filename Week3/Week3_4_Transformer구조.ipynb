{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "592U6lXs3d2t"
      },
      "source": [
        "# Week3_4 Assignment\n",
        "\n",
        "## [BASIC](#Basic) \n",
        "- Encoder & Decoder Layer 코드를 직접 필사하고 각 함수에 주석을 달 수 있다. \n",
        "\n",
        "## [CHALLENGE](#Challenge)\n",
        "- 텐서의 크기(shape)를 계산할 수 있다. \n",
        "\n",
        "## [ADVANCED](#Advanced)\n",
        "- 완성된 transformer 모델의 모든 학습 가능한 파라미터 이름과 크기(shape)를 출력할 수 있다.\n",
        "\n",
        "### Informs\n",
        "이번 과제에서는 \"[Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)\"의 코드를 필사해본다.   \n",
        "\"Annotated Transformer\"는 \"Attention is all you need\" 논문에서 제안한 transformer 모델을 pytorch 라이브러리로 직접 구현한다.   \n",
        "코드 필사를 통해 다음을 배울 수 있다.    \n",
        "- Encoder, Decoder 구조\n",
        "- Attention Mechanism\n",
        "- \"residual connection\", \"layer normalization\" 등의 구조 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoebvnNZ99r-"
      },
      "source": [
        "코드 필사를 시작하기 앞서, transformer 모델의 최종 구조를 살펴보자.    \n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_full.png?raw=true\" width=\"500\" align=\"center\"/>\n",
        "\n",
        "최종 모델은 `EncoderDecoder()` 클래스에 여러 인스턴스를 생성자의 입력 파라미터로 넣어 생성한다.    \n",
        "앞으로 우리는 `EncoderDecoder()` 클래스와 같은 여러 클래스들을 구현하고 연결할 것이다. 따라서 대략적인 클래스간의 관계를 살펴보고 이해한다면 보다 큰 그림을 가지고 코드 필사를 할 수 있을 것이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB6cNaXP99sB"
      },
      "source": [
        "Transformer 모델은 크게 4가지 클래스로 구현된다.    \n",
        "- Frame\n",
        "    - frame 역할을 하는 `EncoderDecoder` 클래스\n",
        "- Input Embedding & Encoding\n",
        "    - 입력값을 벡터화하는 `Embeddings`, `PositionalEncoding`\n",
        "- Encoder & Decoder\n",
        "    - 각 6개 layer를 갖고 있는 `Encoder`, `Decoder`\n",
        "    - layer 1층을 구현한 `EncoderLayer`, `DecoderLayer`\n",
        "- Sublayer\n",
        "    - `EncoderLayer`, `DecoderLayer` 내부에서 사용되는 Sublayer 클래스인 `MultiHeadAttiontion`, `PositionwiseFeedForward`\n",
        "    - Sublayer 클래스들을 연결하는 `SublayerConnection`\n",
        "    \n",
        "아래 좌측 도식에서 각 클래스의 색상은 아래 우측 도식(transformer 구조)의 색상과 맵핑되어 있다.    \n",
        "각 클래스의 역할과 클래스 간 연결 관계를 생각하면서 transformer를 코드로 구현해보자.   \n",
        "\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_map.png?raw=true\" width=\"400\" height=\"400\" align=\"left\"/>\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_transformer.png?raw=true\" width=\"300\" height=\"400\" align=\"right\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaadVYo799sE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import math, copy, time\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OEO0al299sJ"
      },
      "source": [
        "## Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKKyKfqB99sL"
      },
      "source": [
        "### Frame\n",
        "- `EncoderDecoder`\n",
        "\n",
        "아래 도식은 `EncoderDecoder` 클래스의 `forward()`, `encode()`, `decode()` 메소드를 도식화 한 것이다.    \n",
        " \n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_encoderdecoder.png?raw=true\" width=500>\n",
        "\n",
        "\n",
        "- `Generator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MECCTGpt99sP"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Encoder-Decoder 모델\n",
        "  \n",
        "  주요 architecture\n",
        "  - stacked self-sttention \n",
        "  - point-wise fully connected layer\n",
        "  \"\"\"\n",
        "    \n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "      super(EncoderDecoder, self).__init__() # 부모클래스에서 정의해야 하는 변수들을 넣어준다\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.src_embed = src_embed\n",
        "      self.tgt_embed = tgt_embed\n",
        "      self.generator = generator\n",
        "    \n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "      \"\"\"\n",
        "      masked src 와 target sequence를 받음\n",
        "      \"\"\"\n",
        "      return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "    \n",
        "    \n",
        "    def encode(self, src, src_mask):\n",
        "      return self.encoder(self.src_embed(src), src_mask)\n",
        "    \n",
        "    \n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "      return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py2wcYPX99sT"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Standard Linear 와 softmax generation step 선언\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, d_model, vocab):\n",
        "      super(Generator, self).__init__()\n",
        "      self.proj = nn.Linear(d_model, vocab)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "      return F.log_softmax(self.proj(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI-5SRHD99sX"
      },
      "source": [
        "### Encoder\n",
        "- `Encoder`\n",
        "- `EncoderLayer`\n",
        "- `SublayerConnection`\n",
        "- Reference\n",
        "    - Layer Normalization\n",
        "        - [한국어 설명](https://yonghyuc.wordpress.com/2020/03/04/batch-norm-vs-layer-norm/)\n",
        "        - [torch official docs](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)\n",
        "    - Residual Connection\n",
        "        - [한국어 설명](https://itrepo.tistory.com/36)\n",
        "    - pytorch ModuleList\n",
        "        - [torch official docs](https://pytorch.org/docs/1.9.1/generated/torch.nn.ModuleList.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjIjUBjN99sc"
      },
      "outputs": [],
      "source": [
        "def clones(module, N):\n",
        "  \"N개의 동일한 layer를 반환\"\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgglBAyM99se"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  \"\"\"\n",
        "  6개 layer가 쌓여 있는 형태 이다.\n",
        "  \"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "      super(Encoder, self).__init__()\n",
        "      self.layer = clones(layer, N)\n",
        "      self.norm = LayerNorm(layer.size)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, mask):\n",
        "      \"\"\"\n",
        "      각 layer에서 입력받은 x를 전달하고, masking 적용    \n",
        "      \"\"\"\n",
        "      for layer in self.layers:\n",
        "        x = layer(x, mask)\n",
        "      return self.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvGP8Gsd99sg"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    2개의 sub layer에 layer normalization을 적용\n",
        "    layer normalization은 각 sampled의 feature들에 대해 정규화를 적용하는 것    \n",
        "    -> input의 feature들에 대한 평균과 분산을 구해 batch에 있는 각 input을 정규화\n",
        "    \"\"\"\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "      super(LayerNorm, self).__init__()\n",
        "      self.a_2 = nn.Parameter(torch.ones(features)) # module parameter로 여겨지는 tensor\n",
        "      self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "      self.eps = eps\n",
        "    \n",
        "    # layer normalization\n",
        "    def forward(self, x):\n",
        "      mean = x.mean(-1, keepdim=True)\n",
        "      std = x.std(-1, keepdim=True)\n",
        "      \n",
        "      return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "525_O3YE99si"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    residual connection을 위한 class\n",
        "    residual connection은 기존에 학습한 정보를 보존하고, 거기에 추가적으로 학습하는 정보 의미\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, size, dropout):\n",
        "      super(SublayerConnection,self).__init__()\n",
        "      self.norm = LayerNorm(size)\n",
        "      self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x, sublayer):\n",
        "      \"\"\"\n",
        "      동일 사이즈의 sublayer에 residual connection을 적용\n",
        "      \"\"\"\n",
        "      return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlGCPEVp99sk"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "      \"\"\"\n",
        "      multihead attention + feed forward network 두 sublayer로 구성됨\n",
        "      - self attention layer : multihead attention\n",
        "      - feed forward layer : position wise feed forward network\n",
        "      - residual connection  \n",
        "      \"\"\"\n",
        "      super(EncoderLayer, self).__init__()\n",
        "      self.self_attn = self_attn\n",
        "      self.feed_forward = feed_forward\n",
        "      self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "      self.size = size\n",
        "      \n",
        "    def forward(self, x, mask):\n",
        "      \"\"\"\n",
        "      Transformer Architecture의 Encoder Layer를 구성\n",
        "      \"\"\"\n",
        "      x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask)) # multihead attention+ add & norm\n",
        "      return self.sublayer[1](x, self.feed_forward) # feed forward network + add & norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOiYmYWc99sm"
      },
      "source": [
        "### Decoder\n",
        "- `Decoder`\n",
        "- `DecoderLayer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik47frFO99so"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    N개의 layer를 가지는 decoder class N == 6\n",
        "    \"\"\"\n",
        "    def __init__(self, layer, N):\n",
        "      super(Decoder, self).__init__()\n",
        "      self.layers = clones(layer, N)\n",
        "      self.norm = LayerNorm(layer.size)\n",
        "    \n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "      \"\"\"\n",
        "      각 layer에서 순서대로 값을 넘기며 masking\n",
        "      \"\"\"\n",
        "      for layer in self.layers:\n",
        "        x = layer(x, memory, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElsG9P7M99sq"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  \"\"\"\n",
        "  3개의 sublayer로 구성\n",
        "  self_attn : masked multihead attention\n",
        "  self_src : multihead attention\n",
        "  feed_forward : position wise feed forward network \n",
        "  \n",
        "  -> encoder stack의 output에 multi-head attention을 수행\n",
        "  \"\"\"\n",
        "  def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "      super(DecoderLayer, self).__init__()\n",
        "      self.size = size\n",
        "      self.self_attn = self_attn\n",
        "      self.src_attn = src_attn\n",
        "      self.feed_forward = feed_forward\n",
        "      self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "    \n",
        "    \n",
        "  def forward(self, x, memory, src_mask, tgt_mask):\n",
        "      \"\"\"\n",
        "      Transformer Architecture의 Decoder Layer를 구성\n",
        "      \"\"\"\n",
        "      m = memory\n",
        "      x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "      x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "      \n",
        "      return self.sublayer[2](x, self.feed_forward)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhPP8LVw99sr"
      },
      "source": [
        "### Sublayer\n",
        "- `attention` 함수\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_attention.png?raw=true\" width=\"500\" align=\"center\"/>  \n",
        "\n",
        "- `MultiHeadedAttention`\n",
        "- `PositionwiseFeedForward`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o1-iOBu99ss"
      },
      "source": [
        "### Challenge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ochH0n99st"
      },
      "source": [
        "### Q1. 위 도식에 따라 `score`, `p_attn`, `attention` 을 구하라 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- query : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
        "- key : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
        "- value : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
        "- padding_mask: (batch_size, 1, 1, key의 문장 길이)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMYcy8h499sv"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "  \"\"\"\n",
        "  Scaled Dot Product Attention\n",
        "  \"\"\"\n",
        "  d_k = query.size(-1) # d_model/n_head\n",
        "  \n",
        "  score = (query @ key.transpose(-2, -1)) / math.sqrt(query.size(-1)) \n",
        "  # Q * K^T / sqrt(d_k)\n",
        "  \n",
        "  if mask is not None:\n",
        "    score = score.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = F.softmax(score, dim=-1)\n",
        "    \n",
        "  if dropout is not None:\n",
        "    p_attn = dropout(p_attn)\n",
        "    # return[0] = (batch_size, n_head, seq_len, d_k)) \n",
        "    \n",
        "  attention_output = p_attn @ value # matrix multiplication\n",
        "  return attention_output, p_attn\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = torch.randn(3, 5)\n",
        "#print(query.size())\n",
        "key =  torch.randn(3, 5)\n",
        "value = torch.randn(3, 5)\n",
        "\n",
        "score_p = (query @ key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
        "p_attn = F.softmax(score_p, dim=-1)\n",
        "attention_output = (p_attn @ value)\n",
        "\n",
        "\n",
        "print(score_p.shape)\n",
        "print(p_attn.shape)\n",
        "print(attention_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x25aeigL99sw"
      },
      "source": [
        "###Q2. query, key, value가 모두 (m, d_k) shape의 matrix라고 가정할 때, `score`, `p_attn`, `attention`의 shape을 각각 구하라\n",
        "- score : (m, m)\n",
        "- p_attn : (m, m)\n",
        "- attention : (m, d_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHfxLJKz99sx"
      },
      "source": [
        "### (아래의 **Q3을 먼저 풀고 돌아오세요**) Q4.  query, key, value가 모두 (12, 8, 1, 64) shape의 tensor라고 가정할 때 , `score`, `p_attn`, `attention`의 shape을 각각 구하라\n",
        "\n",
        "- score : (12,8,1,1)\n",
        "- p_attn : (12,8,1,1)\n",
        "- attention : (12,8,1,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = torch.randn(12,8,1,64)\n",
        "key = torch.randn(12,8,1,64)\n",
        "value = torch.randn(12,8,1,64)\n",
        "\n",
        "\n",
        "score_p = (query @ key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
        "p_attn = F.softmax(score_p, dim=-1)\n",
        "attention_output = (p_attn @ value)\n",
        "\n",
        "print(score_p.shape)\n",
        "print(p_attn.shape)\n",
        "print(attention_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYnffQE799sy"
      },
      "source": [
        "- `MultiHeadedAttention`\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_multihead.png?raw=true\" width=\"300\" align=\"center\"/>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhFKlJ2b99sz"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "      \"\"\"\n",
        "      - h : attention head의 수 (multi-head attention)\n",
        "      - d_model : model 차원\n",
        "      - dropout : dropout rate\n",
        "      \"\"\"\n",
        "      super(MultiHeadedAttention, self).__init__()\n",
        "      assert d_model % h == 0\n",
        "      # d_v == d_k 로 가정하고 진행\n",
        "      self.d_k = d_model // h\n",
        "      self.h = h\n",
        "      self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "      self.attn = None\n",
        "      self.dropout = nn.Dropout(p=dropout)\n",
        "    \n",
        "    \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "      if mask is not None:\n",
        "        mask = mask.unsqueeze(1) # unsqueeze(1) : (batch_size, 1, seq_len)\n",
        "      n_batches = query.size(0)\n",
        "      \n",
        "      # 1) linear projection 적용\n",
        "      # query, key, value를 각각 서로 다른 linear layer에 통과시킨후  다시 query, key, value 에 할당\n",
        "      query, key, value = \\\n",
        "        [l(x).view(n_batches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]\n",
        "      \n",
        "      # 2) attention\n",
        "      x, self.attn = attention(query, key, value, mask, self.dropout)\n",
        "      \n",
        "      # 3) concat을 이용해 합쳐주기 -> 마지막 linear layer에 통과\n",
        "      x = x.transpose(1, 2).contiguous() \\\n",
        "        .view(n_batches, -1, self.h * self.d_k)\n",
        "      return self.linears[-1](x)\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M46Ensa499s0"
      },
      "source": [
        "### Q3.  query, key, value가 모두 (12, 512) shape의 matrix이고, h 값이 8 이라고 가정할 때, 아래 값의 shape을 각각 구하라\n",
        "\n",
        "- `d_k` (d_k = d_model // h) : 64\n",
        "- `nn.Linear(d_model, d_model)(query)` : (12,512)\n",
        "- `nn.Linear(d_model, d_model)(query).view(nbatches, -1, h, d_k)` : (12,1,8,64)\n",
        "- `nn.Linear(d_model, d_model)(query).view(nbatches, -1, h, d_k).transpose(1,2)` : (12,8,1,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = torch.randn(12, 512)\n",
        "key = torch.randn(12, 512)\n",
        "value = torch.randn(12, 512)\n",
        "\n",
        "d_model = 512\n",
        "\n",
        "h = 8\n",
        "d_k = d_model // h\n",
        "print(d_k)\n",
        "\n",
        "\n",
        "w_q = nn.Linear(d_model, d_model)\n",
        "\n",
        "n_batch = query.size(0)\n",
        "print(w_q(query).size())\n",
        "print(w_q(query).view(n_batch,-1,h,d_k).size())\n",
        "print(w_q(query).view(n_batch,-1,h,d_k).transpose(1,2).size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twZoeFr799s1"
      },
      "source": [
        "- `PositionwiseFeedForward`\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_pwff.png?raw=true\" width=\"300\" align=\"center\"/>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZzpucvQ99s2"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "  \"\"\"\n",
        "  FFN(x) = max(0, xW1 + b1)W2 + b2\n",
        "  input 과 output은 d_model의 차원\n",
        "  내부 layer는 d_model * 4 의 차원\n",
        "  \"\"\"\n",
        "  def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "    super(PositionwiseFeedForward, self).__init__()\n",
        "    self.w_1 = nn.Linear(d_model, d_ff)\n",
        "    self.w_2 = nn.Linear(d_ff, d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqjsUsbu99s3"
      },
      "source": [
        "### Input Embedding & Encoding\n",
        "- `Embeddings`\n",
        "    - [pytorch official docs](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBVJFurO99s3"
      },
      "outputs": [],
      "source": [
        "class Embeddings(nn.Module):\n",
        "  \"\"\"\n",
        "  x (연속적인 토큰)를 fixed vocab size의 lookup 테이블에서 d_model 사이즈의 Embedding vector로 변환\n",
        "  \"\"\"\n",
        "    def __init__(self, d_model, vocab):\n",
        "      super(Embeddings, self).__init__()\n",
        "      self.lut = nn.Embedding(vocab, d_model)\n",
        "      self.d_model = d_model\n",
        "    \n",
        "    def forward(self, x):\n",
        "      return self.lut(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po31qs_A99s5"
      },
      "source": [
        "- `PositionalEncoding`\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_pe.png?raw=true\" width=\"500\" align=\"center\"/>  \n",
        "\n",
        "- `position` 변수 설명\n",
        "    - 모든 position (=최대 토큰 개수)의 값을 갖고 있는 matrix\n",
        "- `div_term` 변수 설명\n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_div.png?raw=true\" width=\"500\" align=\"center\"/>  \n",
        "- `Embedding` + `Encoding` 도식화 \n",
        "\n",
        "<img src=\"https://github.com/ChristinaROK/PreOnboarding_AI_assets/blob/36a670a7b6233d5218a495150beb337a899ecb70/week3/week3_3_emb_enc.png?raw=true\" width=\"400\" align=\"center\"/>  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP-_an3x99s5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    # 엠베딩 된 3차원 텐서 (nbatches, max_len, d_model))에 positional encoding을 더해 반환\n",
        "    def __init__(self, d_model, dropout, max_len = 5000):\n",
        "      super(PositionalEncoding, self).__init__()\n",
        "      self.dropout = nn.Dropout(p=dropout)\n",
        "      \n",
        "      pe = torch.zeros(max_len, d_model)\n",
        "      position = torch.arange(0, max_len).unsqueeze(1)\n",
        "      div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "      pe[:, 0::2] = torch.sin(position * div_term)\n",
        "      pe[:, 1::2] = torch.cos(position * div_term)\n",
        "      pe = pe.unsqueeze(0)\n",
        "      self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      x = x+Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
        "      \n",
        "      return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNf13Gkm99s6"
      },
      "source": [
        "### Q4.  max_len이 512이고, d_model이 512라고 가정할 때, `position`과 `div_term`의 shape을 구하라\n",
        "\n",
        "- `position` : 512,1\n",
        "- `div_term` : 256,1\n",
        "- `position * div_term` : 512, 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rri-daP399s7"
      },
      "source": [
        "### Advanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3ZixTN199s8"
      },
      "source": [
        "### Finally Build Model\n",
        "- Xavier Initialization\n",
        "    - [한국어 자료](https://huangdi.tistory.com/8)\n",
        "    - [pytorch official docs](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPdGsCiC99s8"
      },
      "outputs": [],
      "source": [
        "def make_model(src_vocab, tgt_vocab, \n",
        "               N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn),\n",
        "                             c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab))\n",
        "    \n",
        "    # 파라미터 초기화\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform(p)\n",
        "            \n",
        "    return model\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIDN1DSd99s-"
      },
      "outputs": [],
      "source": [
        "model = make_model(10,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljRK80Lo99s_"
      },
      "source": [
        "### Q5. 위 코드로 만든 모델의 모든 파라미터의 이름과 크기 (shape) 을 출력하라"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BHubCUOh99tA"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21364/2684763089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print all parameter's name, shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# print all parameter's name, shape\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Week3_4_assginment.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8eba5190429ec69ed9142d9af0d6e9d793f6f50f515fafbe5d718ad04466bd4c"
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
